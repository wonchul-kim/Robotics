{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "\n",
    "Before we dive into code that utilizes Bayes' rule, let's review what we've learned in the previous lesson.\n",
    "\n",
    "We've seen that Bayes' rule allows us to improve a <B>prior</B> probability by incorporating <B>new evidence</B> (from observed data or tests) and forming a new <B>posterior</B> probability. It does this through a series of mathematical steps.\n",
    "\n",
    "To describe the steps, I'll be using the notation *H* for hypothesis (ex. the likelihood that a car is in a certain location or that a person has cancer, etc.), and _T_ for observed test/sensor data (ex. a car sees the color green or a positive medical test result is returned). For example, P(T∣$\\neg$H) is the probability of sensor reading occurring given that the hypothesis has not occurred."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prior probabilities\n",
    "\n",
    "The first step in Bayes' rule is to determine any prior probabilities. Ask yourself, based on previous data, how likely is a hypothesis, or specific event, H to happen?\n",
    "\n",
    "   * Determine P(H)\n",
    "   * Once you have P(H), you can derive P($\\neg$H)\n",
    "\n",
    "#### 2. Conditional/test probabilities\n",
    "\n",
    "You should also know, through sensor or test data collection, how likely a certain test or sensor reading is to occur given that the hypothesis H has or has not occurred.\n",
    "\n",
    "   * Determine P(T∣H) and P(T∣$\\neg$H)\n",
    "   * Once you have P(T∣H), you can derive P($\\neg$T∣H)\n",
    "\n",
    "Steps 1 and 2 give you all the information you need to perform Bayes' rule, and form a prediction about how likely a hypothesis is to be true given certain observed, related data.\n",
    "\n",
    "#### 3. Joint Probabilities\n",
    "\n",
    "The next step is to calculate the four joint probabilities of the prior and the test probabilities. Two examples are given below.\n",
    "\n",
    "   * P(T, H) = P(T|H)$\\cdot$P(H)\n",
    "   * Likewise, P(T,$\\neg$H)=P(T∣$\\neg$H)$\\cdot$P($\\neg$H)\n",
    "\n",
    "#### 4. Total probabilities\n",
    "\n",
    "You'll then need to determine the total probability of a test result or sensor reading, so that you can use this value to normalize the posterior probability (which is the last step of Bayes' rule. The total probability of a test result is the sum of the joint probabilities in which that test result occurs. An example is given below.\n",
    "\n",
    "   * P(T) = P(T,H)+P(T,$\\neg$H)\n",
    "\n",
    "#### 5. Posterior probability (last step)\n",
    "\n",
    "The last step is to determine the probability of an event given a sensor reading or certain test data. And this is given by Bayes' rule. An example is shown below.\n",
    "\n",
    "   * P(H|T) = $\\frac{P(T|H)\\cdot P(H)} {P(T)}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
